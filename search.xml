<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>YARN 在 security 集群中使用统一用户运行 Container</title>
    <url>/2019/11/20/yarn-limit-user-in-secure-mode/</url>
    <content><![CDATA[<p>在我们的工作过程中，随着业务越来越多，Hadoop 集群规模也越来越大，同时对集群的安全性也越来越高，最原始的 SIMPLE 验证方式已经无法满足需求了，因此，我们决定使用 kerberos, 开启集群的安全验证: Run Hadoop in Secure Mode。</p><p>在实践中过程中，我们发现在 Secure Mode 时，NM 必须使用 LinuxContainerExecutor，如果使用 DefaultContainerExecutor 的话，MR 任务会在 reduce shuffle 阶段失败退出，参见<a href="https://issues.apache.org/jira/browse/YARN-1432" target="_blank" rel="noopener">YARN-1432</a>。同时，LCE 会使用任务提交用户 JobUser 来运行 Container，如果 NM 上不存在 JobUser，任务就会失败退出。 </p><a id="more"></a>

<p>其实简单想想就能理解 Hadoop 这样设计的逻辑是为了实现用户隔离，保证用户任务和数据的安全，但是在实践过程中，由于我们集群中用户过多，在 NM 上逐一添加用户过于繁琐，而且后续维护起来比较麻烦，因此，我们决定修改这块的代码逻辑，使 NM 在 Secure Mode 下支持使用统一的 yarn 用户来执行任务。</p>
<h2 id="原始逻辑解析"><a href="#原始逻辑解析" class="headerlink" title="原始逻辑解析"></a>原始逻辑解析</h2><p>为了实现我们的目的，先得了解 NM 这块代码的实现逻辑，所以我对这块的代码逻辑进行了梳理，发现安全用户限制的逻辑存在于 LinuxContainerExecutor 和 SecureIOUtils 两个类中。</p>
<h3 id="LinuxContainerExecutor"><a href="#LinuxContainerExecutor" class="headerlink" title="LinuxContainerExecutor"></a>LinuxContainerExecutor</h3><p>LCE 在初始化，启动以及清理 container 之前，都会调用 <code>getRunAsUser(jobUser)</code> 方法获取该 container 实际运行时该使用的用户，再使用该用户去对 container 执行相应的操作。</p>
<p>如果集群未开启安全验证方式（使用 SIMPLE 验证方式： 如果配置 nonsecure 模式下限制用户时，getRunAsUser 返回统一的用户，默认是 nobody。如果配置不限制用户时，getRunAsUser 返回任务提交用户。</p>
<p>如果集群开启了安全验证方式 (使用 kerberos 验证方式)： getRunAsUser 返回任务提交用户。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Determine if UserGroupInformation is using Kerberos to determine</span></span><br><span class="line"><span class="comment"> * user identities or is relying on simple authentication</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> true if UGI is working in a secure environment</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">isSecurityEnabled</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> !isAuthenticationMethodEnabled(AuthenticationMethod.SIMPLE);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// nonsecure 模式下是否限制用户，默认 true</span></span><br><span class="line"><span class="keyword">boolean</span> containerLimitUsers = conf.getBoolean(</span><br><span class="line">  <span class="string">"yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users"</span>, <span class="keyword">true</span>);</span><br><span class="line"><span class="comment">// nonsecure 模式下默认使用的本地用户， 默认 nobody</span></span><br><span class="line">String nonsecureLocalUser = conf.get(</span><br><span class="line">  <span class="string">"yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user"</span> ,<span class="string">"nobody"</span>);</span><br><span class="line"></span><br><span class="line"><span class="function">String <span class="title">getRunAsUser</span><span class="params">(String user)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (UserGroupInformation.isSecurityEnabled() ||</span><br><span class="line">      !containerLimitUsers) &#123;</span><br><span class="line">    <span class="keyword">return</span> user;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> nonsecureLocalUser;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>LCE 获取到实际用户后，会去调用 container-executor 二进制可执行文件来初始化和启动 container，container-executor 在启动时会执行 set_user 函数来设置 container 实际的执行用户，在这个函数中又会调用 check_user 函数，对该用户进行一系列的校验，主要包括：不是 root， UID 大于配置的 minUid，该用户本地实际存在以及不在禁用用户列表里。当校验不通过时，就会报错退出。所以，当 LCE 传递进来的指定用户在机器上不存在时，container 就会失败退出。</p>
<p>container-executor.c</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Is the user a real user account?</span></span><br><span class="line"><span class="comment"> * Checks:</span></span><br><span class="line"><span class="comment"> *   1. Not root</span></span><br><span class="line"><span class="comment"> *   2. UID is above the minimum configured.</span></span><br><span class="line"><span class="comment"> *   3. Not in banned user list</span></span><br><span class="line"><span class="comment"> * Returns NULL on failure</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function">struct passwd* <span class="title">check_user</span><span class="params">(<span class="keyword">const</span> <span class="keyword">char</span> *user)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (<span class="built_in">strcmp</span>(user, <span class="string">"root"</span>) == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="built_in">fprintf</span>(LOGFILE, <span class="string">"Running as root is not allowed\n"</span>);</span><br><span class="line">    fflush(LOGFILE);</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">char</span> *min_uid_str = get_section_value(MIN_USERID_KEY, &amp;executor_cfg);</span><br><span class="line">  <span class="keyword">int</span> min_uid = DEFAULT_MIN_USERID;</span><br><span class="line">  <span class="keyword">if</span> (min_uid_str != <span class="literal">NULL</span>) &#123;</span><br><span class="line">    <span class="keyword">char</span> *end_ptr = <span class="literal">NULL</span>;</span><br><span class="line">    min_uid = strtol(min_uid_str, &amp;end_ptr, <span class="number">10</span>);</span><br><span class="line">    <span class="keyword">if</span> (min_uid_str == end_ptr || *end_ptr != <span class="string">'\0'</span>) &#123;</span><br><span class="line">      <span class="built_in">fprintf</span>(LOGFILE, <span class="string">"Illegal value of %s for %s in configuration\n"</span>,</span><br><span class="line">	      min_uid_str, MIN_USERID_KEY);</span><br><span class="line">      fflush(LOGFILE);</span><br><span class="line">      <span class="built_in">free</span>(min_uid_str);</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">free</span>(min_uid_str);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">passwd</span> *<span class="title">user_info</span> = <span class="title">get_user_info</span>(<span class="title">user</span>);</span></span><br><span class="line">  <span class="keyword">if</span> (<span class="literal">NULL</span> == user_info) &#123;</span><br><span class="line">    <span class="built_in">fprintf</span>(LOGFILE, <span class="string">"User %s not found\n"</span>, user);</span><br><span class="line">    fflush(LOGFILE);</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (user_info-&gt;pw_uid &lt; min_uid &amp;&amp; !is_whitelisted(user)) &#123;</span><br><span class="line">    <span class="built_in">fprintf</span>(LOGFILE, <span class="string">"Requested user %s is not whitelisted and has id %d,"</span></span><br><span class="line">	    <span class="string">"which is below the minimum allowed %d\n"</span>, user, user_info-&gt;pw_uid, min_uid);</span><br><span class="line">    fflush(LOGFILE);</span><br><span class="line">    <span class="built_in">free</span>(user_info);</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">char</span> **banned_users = get_section_values(BANNED_USERS_KEY, &amp;executor_cfg);</span><br><span class="line">  banned_users = banned_users == <span class="literal">NULL</span> ?</span><br><span class="line">    (<span class="keyword">char</span>**) DEFAULT_BANNED_USERS : banned_users;</span><br><span class="line">  <span class="keyword">char</span> **banned_user = banned_users;</span><br><span class="line">  <span class="keyword">for</span>(; *banned_user; ++banned_user) &#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">strcmp</span>(*banned_user, user) == <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="built_in">free</span>(user_info);</span><br><span class="line">      <span class="keyword">if</span> (banned_users != (<span class="keyword">char</span>**)DEFAULT_BANNED_USERS) &#123;</span><br><span class="line">        free_values(banned_users);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="built_in">fprintf</span>(LOGFILE, <span class="string">"Requested user %s is banned\n"</span>, user);</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (banned_users != <span class="literal">NULL</span> &amp;&amp; banned_users != (<span class="keyword">char</span>**)DEFAULT_BANNED_USERS) &#123;</span><br><span class="line">    free_values(banned_users);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> user_info;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="SecureIOUtils"><a href="#SecureIOUtils" class="headerlink" title="SecureIOUtils"></a>SecureIOUtils</h3><p>SecureIOUtils 是一个公用的提供安全的读写本地文件接口的工具类，当集群开启安全验证之后，SecureIOUtils 提供的读写接口会对发起读写用户与本地文件的属主进行对比，如果不一致，则抛出 IOException。</p>
<p>MR 的 ShuffleHandler 在读取 map 输出的 spill 文件时会调用 SecureIOUtils，ShuffleHandler 读时使用的用户任务提交用户，当用户与文件属主不一致时，shuffle 就会一直失败，最终任务的 reduce 因为 shuffle 失败而退出。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">checkStat</span><span class="params">(File f, String owner, String group, </span></span></span><br><span class="line"><span class="function"><span class="params">    String expectedOwner, </span></span></span><br><span class="line"><span class="function"><span class="params">    String expectedGroup)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">boolean</span> success = <span class="keyword">true</span>;</span><br><span class="line">  <span class="keyword">if</span> (expectedOwner != <span class="keyword">null</span> &amp;&amp;</span><br><span class="line">      !expectedOwner.equals(owner)) &#123;</span><br><span class="line">    <span class="keyword">if</span> (Path.WINDOWS) &#123;</span><br><span class="line">      UserGroupInformation ugi =</span><br><span class="line">          UserGroupInformation.createRemoteUser(expectedOwner);</span><br><span class="line">      <span class="keyword">final</span> String adminsGroupString = <span class="string">"Administrators"</span>;</span><br><span class="line">      success = owner.equals(adminsGroupString)</span><br><span class="line">          &amp;&amp; ugi.getGroups().contains(adminsGroupString);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      success = <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (!success) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> IOException(</span><br><span class="line">        <span class="string">"Owner '"</span> + owner + <span class="string">"' for path "</span> + f + <span class="string">" did not match "</span> +</span><br><span class="line">            <span class="string">"expected owner '"</span> + expectedOwner + <span class="string">"'"</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="优化方案"><a href="#优化方案" class="headerlink" title="优化方案"></a>优化方案</h2><p>根据上述的代码逻辑分析，我们发现其实想要实现我们的目的其实是很简单的，只要修改两点就可以做到：</p>
<ul>
<li>LCE getRunAsUser 支持 security 模式下返回统一用户</li>
<li>SecureIOUtils 支持 security 模式下用户读取不属于自己的文件</li>
</ul>
<p>代码修改实现起来也很简单，但是我们还是需要考虑一下怎样实现更加优雅，能更好的兼容原有的功能。说到这，额外多说一句，在日常的项目开发工作中，有很多朋友都喜欢以实现功能优先，不考虑其他的问题，先使用最快最简单的方式实现。比如说上述两个功能，很多朋友可能就直接修改 LCE 的 getRunAsUser 方法使之在任何情况下都返回同一个基于配置用户，更有甚者直接硬编码返回 <code>yarn</code> 用户，然后 SecureIOUtils 中直接去除安全模式时的用户比较。这样一来基本没什么修改就实现了功能。</p>
<p>对于这种开发方式，其实我是不太赞同的，因为这种开发方式确实能够快速满足当前需求，但是往往都是以牺牲掉代码的兼容性和扩展性为代价的。这种方式，对于一些比较小的项目，可能还能够适用，对于类似 hadoop 这种大型的持续开发演进的系统，这种方式就是不可取的。比如我刚才举例的实现方式，确实快，可能也就改了 2 行代码，但是它的后果就是，修改上线后的 NM 不再支持用户权限隔离功能了，后续如果业务真有了这个需求，也是没办法支持的，除非把代码再改回来。</p>
<p>因此，在 hadoop 这种大型系统的功能开发工作中，我们在实现功能的同时，更要考虑实现功能的方式与系统本身的兼容性，以及功能后续的扩展性，以防止当前的实现方式在后续带来更多的问题。具体到本文中的功能，我们首先应该考虑在保证在 security 模式下 NM 原有的任务用户隔离功能的基础上，同时支持 NM 使用同一用户来运行所有 container 。我们都知道 hadoop 基于配置的，很多功能属性的启用都是通过配置，所以我们在实现该功能时，也应该通过配置来实现。具体配置如下：</p>
<p>YarnConfiguration.java</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">// secure-mode 模式下是否开启用户限制，默认为 true, 即使用同一用户运行 container</span></span><br><span class="line"><span class="comment">// 设置成为 false 时，则与原始逻辑一致 </span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String NM_SECURE_MODE_LIMIT_USERS = NM_PREFIX +</span><br><span class="line">    <span class="string">"linux-container-executor.secure-mode.limit-users"</span>;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">boolean</span> DEFAULT_NM_SECURE_MODE_LIMIT_USERS = <span class="keyword">true</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// secure-mode 模式下开启用户限制时使用的用户，默认 nobody，建议配置为 yarn</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String NM_SECURE_MODE_LOCAL_USER_KEY = NM_PREFIX +</span><br><span class="line">    <span class="string">"linux-container-executor.secure-mode.local-user"</span>;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String DEFAULT_NM_SECURE_MODE_LOCAL_USER = <span class="string">"nobody"</span>;</span><br></pre></td></tr></table></figure>
<p>CommonConfigurationKeys.java</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">// secure-mode 模式下是否限制用户只能读写属于自己的本地文件，默认是 true，与原始逻辑一致</span></span><br><span class="line"><span class="comment">// 设置成 false 时，会跳过文件用户检测，及允许用户读取不属于自己的本地文件。</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String HADOOP_SECURITY_IO_LIMIT_USER_KEY =</span><br><span class="line">    <span class="string">"hadoop.security.io.limit-user"</span>;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">boolean</span> HADOOP_SECURITY_IO_LIMIT_USER_DEFAULT =<span class="keyword">true</span>;</span><br></pre></td></tr></table></figure>

<p>具体代码就不全部贴出来了，参见基于 3.2.0 分支实现的 <a href="yarn_limit_user_in_securemode-branch-3.2.0.patch">branch-3.2.0.patch</a> 即可。patch 合并之后，通过设置以下配置我们就可以实现在 security 模式下，NM 统一使用 yarn 用户来运行任务。</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.linux-container-executor.secure-mode.limit-users<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.linux-container-executor.secure-mode.local-user<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.security.io.limit-user<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Hadoop-YARN</category>
      </categories>
      <tags>
        <tag>Yarn</tag>
        <tag>LinuxContainerExecutor</tag>
        <tag>Security</tag>
      </tags>
  </entry>
  <entry>
    <title>HDFS 问题总结</title>
    <url>/2019/11/01/hdfs-problems-collection/</url>
    <content><![CDATA[<p>在日常维护 HDFS 集群以及为用户提供技术支持时，我们经常会遇到各种 HDFS 相关异常问题，对于一些常见的问题，我们可能知道如何去解决，所以处理起来会比较快。但是当遇到一些不常见的问题时，我们可能没办法根据异常信息直接找到解决方法，可能需要查找一些资料，或者深入源码层面查找问题所在，处理起来比较费时费力，很可能对集群的业务造成影响。</p><a id="more"></a>
<p>因此，将实际生产环境中 HDFS 集群出现的问题进行总结是有必要的。在本文中，我会把我在集群运维过程遇到的一些有代表性的问题进行总结，包括异常信息，产生原因以及解决办法，以便为后续的运维工作提供一个快速参照，也希望能给大家带来一定的参考。</p>
<h2 id="文件未正常关闭"><a href="#文件未正常关闭" class="headerlink" title="文件未正常关闭"></a>文件未正常关闭</h2><h3 id="异常信息"><a href="#异常信息" class="headerlink" title="异常信息"></a>异常信息</h3><p>主要异常信息有以下几种：</p>
<ul>
<li><p>Cannot obtain block length<br>出现在读取未正常关闭文件时</p>
</li>
<li><p>Mismatch in length of source<br>出现在 distcp 文件后，对比源文件与复制文件长度时</p>
</li>
</ul>
<h3 id="产生原因"><a href="#产生原因" class="headerlink" title="产生原因"></a>产生原因</h3><p>正常 HDFS 客户端向 HDFS 写入数据完成时，会向 NameNode 发起 <code>completeFile</code> 的操作，NN 端会 <code>commit &amp; complete</code> 文件的最后一个 block，然后更新文件 INode 信息，主要是加入 last block 长度， 再 <code>finalize INodeFile</code> 关闭文件，释放文件租约。此时文件对于客户端来说，就是正常关闭的完整文件。</p>
<p>但是如果写入数据时发生了异常，比如客户端崩溃或者 namenode 异常等，completeFile 未成功发起或者完成，就会导致文件最后一个 block 可能未正常关闭，INodeFile 记录的文件长度与实际写入的长度不匹配，租约也无法正常释放。此时文件对于客户端来讲，是未关闭的异常状态，也就是 <code>openforwrite</code> 的状态，此时去读文件时，就会出现上述的异常状态。</p>
<h3 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h3><p>这种情况的解决方案是先找出未正常关闭的文件，然后通过手动释放租约，关闭文件。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">1. 使用 fsck 找出未正常关闭文件</span><br><span class="line">hdfs fsck path -openforwrite </span><br><span class="line"></span><br><span class="line">对于 federation 集群需要指定 defaultFS</span><br><span class="line">hdfs fsck -Dfs.defaultFS=hdfs://nameservice:8020/ path -openforwrite </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">2. 手动释放租约</span><br><span class="line">hdfs debug recoverLease -path openfile -retries 3</span><br></pre></td></tr></table></figure>

<h2 id="安全集群-kerberos-无法访问非安全集群"><a href="#安全集群-kerberos-无法访问非安全集群" class="headerlink" title="安全集群 (kerberos) 无法访问非安全集群"></a>安全集群 (kerberos) 无法访问非安全集群</h2><h3 id="异常信息-1"><a href="#异常信息-1" class="headerlink" title="异常信息"></a>异常信息</h3><p>HDFS 支持使用 kerberos 认证作为用户权限校验工具，开启的集群的 security 模式。 安全模式的配置大致为</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.security.authentication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>kerberos<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.security.authorization<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>当 security 集群 客户端通过指定 namenode 地址访问另一个 non security 的的集群时会有以下报错：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">hadoop fs -ls hdfs:master001.mars.sjs.ted:<span class="number">8020</span>/user </span><br><span class="line"></span><br><span class="line"><span class="number">19</span>/<span class="number">05</span>/<span class="number">31</span> <span class="number">17</span>:<span class="number">14</span>:<span class="number">34</span> INFO configfile.ConfigFileHasClientPlugin: Get the user info successfully, login user : hdfs</span><br><span class="line">ls: Failed on local exception: java.io.IOException: Server asks us to fall back to SIMPLE auth, but <span class="keyword">this</span> client is configured to only allow secure connections.; Host Details : local host is: <span class="string">"cloud_dev.gd.ted/10.135.43.214"</span>; destination host is: <span class="string">"master001.mars.sjs.ted"</span>:<span class="number">8020</span>;</span><br></pre></td></tr></table></figure>

<h3 id="产生原因-1"><a href="#产生原因-1" class="headerlink" title="产生原因"></a>产生原因</h3><p>当客户端开启了安全认证模式，而请求的 service 服务使用 SIMPLE 模式，未开启安全认证的时候 IPC Client 在与 server 端建立连接时，会因为验证方式不一致而抛出此异常。</p>
<h3 id="解决方式"><a href="#解决方式" class="headerlink" title="解决方式"></a>解决方式</h3><p>解决方法是在客户端添加配置，允许 security 的客户端连接 non security &amp; simple 模式的服务端建立连接。</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>   </span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>ipc.client.fallback-to-simple-auth-allowed<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="datanode-域名无法解析"><a href="#datanode-域名无法解析" class="headerlink" title="datanode 域名无法解析"></a>datanode 域名无法解析</h2><h3 id="异常信息-2"><a href="#异常信息-2" class="headerlink" title="异常信息"></a>异常信息</h3><p>在客户端读写 HDFS 数据的时候，有时会出现以下的异常</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">java.nio.channels.UnresolvedAddressException</span><br><span class="line">	at sun.nio.ch.Net.checkAddress(Net.java:<span class="number">101</span>)</span><br><span class="line">	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:<span class="number">622</span>)</span><br><span class="line">	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:<span class="number">192</span>)</span><br><span class="line">	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:<span class="number">530</span>)</span><br></pre></td></tr></table></figure>

<h3 id="产生原因-2"><a href="#产生原因-2" class="headerlink" title="产生原因"></a>产生原因</h3><p>当客户端向 HDFS 发起读写请求时，NameNode 会根据目标文件的 block 存储位置返回一组相应的 datanode 节点给客户端，默认状况下，客户端根据返回的 datanode 的域名和端口信息，发起 socket 连接，进行数据读写。</p>
<p>在集群维护过程中，我们发现有些小型集群，为了省事，未在 dns 服务器上配置可解析的域名，而是所有 datanode 节点本地配置域名，同时在所有 datanode 节点上的 /etc/hosts 里面添加映射来完成域名解析。这种情况下，客户端在读写集群时，根据 datanode 域名去解析 ip 时，就会有这种无法解析域名 UnresolvedAddressException 的报错。</p>
<h3 id="解决方法-1"><a href="#解决方法-1" class="headerlink" title="解决方法"></a>解决方法</h3><p>这种状况的解决方式有两种：  </p>
<p>首先第一种就是跟集群上的 datanode 节点一样，将所有的节点域名映射添加到 /etc/hosts 里，这种方式比较笨，而且难以维护，必须要跟这集群节点信息的更新而更新，所以不建议这样解决。</p>
<p>第二种方式是将客户端禁止默认使用域名进行连接，这样客户端就会默认使用节点 ip 进行连接，也就跳过了域名解析的问题。客户端只需要在配置 <code>dfs.client.use.datanode.hostname=false</code> 即可，且不需要频繁更改，所以推荐使用这种解决方式。</p>
<h2 id="datanode-注册失败，机架信息异常"><a href="#datanode-注册失败，机架信息异常" class="headerlink" title="datanode 注册失败，机架信息异常"></a>datanode 注册失败，机架信息异常</h2><h3 id="异常信息-3"><a href="#异常信息-3" class="headerlink" title="异常信息"></a>异常信息</h3><p>当集群新增 datanode 节点，启动时无法向 NN 成功注册，异常信息如下</p>
<p>NN 端 异常：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">org.apache.hadoop.net.NetworkTopology: Error: can<span class="string">'t add leaf node /J/HD-1100/10.140.49.36:50010 at depth 3 to topology:</span></span><br><span class="line"><span class="string">org.apache.hadoop.net.NetworkTopology$InvalidTopologyException: Failed to add /J/HD-1164/10.140.83.70:50010: You cannot have a rack and a non-rack node at the same level of the network topology.</span></span><br><span class="line"><span class="string">	at org.apache.hadoop.net.NetworkTopology.add(NetworkTopology.java:415)</span></span><br><span class="line"><span class="string">	at org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.registerDatanode(DatanodeManager.java:980)</span></span><br><span class="line"><span class="string">    ...</span></span><br></pre></td></tr></table></figure>

<p>DN 端 异常：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.net.NetworkTopology$InvalidTopologyException): Failed to add /J/HD-<span class="number">1164</span>/<span class="number">10.140</span>.83.70:<span class="number">50010</span>: You cannot have a rack and a non-rack node at the same level of the network topology.</span><br><span class="line">        at org.apache.hadoop.net.NetworkTopology.add(NetworkTopology.java:<span class="number">415</span>)</span><br><span class="line">        at org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.registerDatanode(DatanodeManager.java:<span class="number">980</span>)</span><br><span class="line">        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.registerDatanode(FSNamesystem.java:<span class="number">5218</span>)</span><br><span class="line">        ...</span><br></pre></td></tr></table></figure>

<h3 id="产生原因-3"><a href="#产生原因-3" class="headerlink" title="产生原因"></a>产生原因</h3><p>datanode 节点的机架信息代表着 datanode 在集群的网络拓扑结构中所在的位置， NN 通过机架信息来计算节点之间的距离，进而通过选用距离最近的节点，提升集群读写任务的本地性，达到读写加速的效果。</p>
<p>机架信息通常使用 /d/r/n 这种3层机构来标识， d 为 data center ，表示数据中心， r 为rack， 表示机架信息， n 为 node，标识节点信息。</p>
<p>通过追踪 datanode 注册模块的代码，我们发现该异常产生原因是 Namenode 通过配置 <code>net.topology.table.file.name</code> 指定的节点机架信息配置文件来维护所有节点的机架信息。如果配置文件中不存在某个节点的机架信息，该节点的机架信息就为默认的 <code>/default-rack</code> ， NN 使用机架信息中的 ‘/‘ 数量来标识机架信息的深度。<strong>最为重要的，一个集群只允许有一种深度的机架信息，所以新增的 datanode 的机架深度必须跟已有的机架信息深度完全一致。</strong> </p>
<p>所以，当新增节点的机架信息与原来节点机架信息深度不一致时，就会出现此异常。具体可能是新增节点未配置机架信息，使用的 <code>/default-rack</code> 与原来节点不一致，也可能是配置时，配置的机架深度与原来节点不一致。</p>
<h3 id="解决方式-1"><a href="#解决方式-1" class="headerlink" title="解决方式"></a>解决方式</h3><p>检查 <code>net.topology.table.file.name</code> 指定的机架信息配置文件中，新节点的机架信息是否配置了，如果未配置，按照之前的规则添加正确的机架信息，如果配置了，检查是否正确，如果不正确，修正即可。如果是正确的，可能要考虑之前节点的机架信息是否配置上了，很有可能之前的机架信息没有配置正确，用的都是 <code>/default-rack</code></p>
]]></content>
      <categories>
        <category>Hadoop-HDFS</category>
      </categories>
      <tags>
        <tag>HDFS</tag>
        <tag>trouble shooting</tag>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title>Yarn 使用 Cgroup 实现任务资源限制</title>
    <url>/2019/10/20/yarn-cgroup-usage/</url>
    <content><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>Linux CGroup 全称是 Linux Control Group，是 Linux 内核提供的一个用来限制进程资源使用的功能，支持如 CPU, 内存，磁盘 IO 等资源的使用限制。用户可以使用 CGroup 对单个进程或者一组进程进行精细化的资源限制，具体使用方式可以查看参考文档。</p><p>目前， Yarn NodeManager 能够使用 CGroup 来限制所有 containers 的资源使用，主要是 CPU 资源。如果不用 CGroup， 在 NM 端很难实现对 container 的 CPU 使用进行限制。默认状态下， container 的 CPU 使用是没有限制的，container 申请了 1 vcore ，实际上能够使用所有的 CPU 资源。所以如果 NM 上分配了一个 vcore 申请较少实际上 CPU 使用极高的任务，常常会导致节点上运行的所有的任务都延时。</p><a id="more"></a>

<p>NM 运行时，可以通过 ContainersMonitor 线程监控 container 内存和 CPU 使用。对于 container 内存使用， 一旦发现其超出申请内存大小，就会立即发起 kill container 命令，回收 container 的资源。ContainersMonitor 虽然也支持 CPU 使用监控，但是 CPU 资源不像内存资源，其使用量的峰值是基本上可以确定的，在所有机器或者系统上都基本一致。 CPU 受限于 CPU 硬件性能， 同一个任务在不同的机器上的 CPU 使用率可能差异巨大，所以不能发现 container CPU 使用超过申请大小就 kill container 。同时，由于 container 都是由子进程的方式启动的， NM 也是很难通过直接控制 container 运行和暂停来调整其 CPU 使用率。 因此，在没有 CGroup 功能的情况下， NM 是很难直接限制 container 的 CPU 使用的。</p>
<p>所以接下来我们主要介绍 Yarn 如何启用 CGroup 来限制 containers CPU 资源占用。</p>
<h2 id="启用"><a href="#启用" class="headerlink" title="启用"></a>启用</h2><p>NM 启用 CGroup 功能主要需要在 <code>yarn-site.xml</code> 里设置以下配置：</p>
<h3 id="1-启用-LCE-："><a href="#1-启用-LCE-：" class="headerlink" title="1. 启用 LCE ："></a>1. 启用 LCE ：</h3><p>在 Nodemanager 中， CGroup 功能集成在 LinuxContainerExecutor 中，所以要使用 CGroup 功能，<strong>必须</strong>设置 container-executor 为 LinuxContainerExecutor. 同时需要配置 NM 的 Unix Group，这个是可执行的二进制文件 container-executor 用来做安全验证的，需要与 container-executor.cfg 里面配置的一致。 详细配置可参见 <a href="yarn-container-executour">Yarn ContainerExecutor 配置与使用</a>。</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.container-executor.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor<span class="tag">&lt;<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.linux-container-executor.group<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop<span class="tag">&lt;<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="2-启用-CGroup-："><a href="#2-启用-CGroup-：" class="headerlink" title="2. 启用 CGroup ："></a>2. 启用 CGroup ：</h3><p>LinuxContainerExecutor 并不会强制开启 CGroup 功能， 如果想要开启CGroup 功能，<strong>必须</strong>设置 resource-handler-class 为 CGroupsLCEResourceHandler.</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.linux-container-executor.resources-handler.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.yarn.server.nodemanager.util.CgroupsLCEResourcesHandler<span class="tag">&lt;<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="3-配置-Yarn-CGroup-目录："><a href="#3-配置-Yarn-CGroup-目录：" class="headerlink" title="3. 配置 Yarn CGroup 目录："></a>3. 配置 Yarn CGroup 目录：</h3><p>NM 通过 <code>yarn.nodemanager.linux-container-executor.cgroups.hierarchy</code> 配置所有 Yarn Containers 进程放置的 CGroup 目录。</p>
<p>如果系统的 CGroup 未挂载和配置，可以在系统上手动挂载和配置和启用 CGroup 功能，也可以通过设置<br><code>yarn.nodemanager.linux-container-executor.cgroups.mount</code> 为 true，同时设置 CGroup 挂载路径 <code>yarn.nodemanager.linux-container-executor.cgroups.mount-path</code> 来实现 NM 自动挂载 CGroup (不建议这样用，问题挺多)。</p>
<p>如果系统的 CGroup 已经挂载且配置完成，而且 Yarn 用户有 CGroup cpu 子目录的写入权限，NM 会在 cpu 目录下创建 <code>hadoop-yarn</code> 目录 ，如果该目录已经存在，保证 yarn 用户有写入权限即可。</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.linux-container-executor.cgroups.hierarchy<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>/hadoop-yarn<span class="tag">&lt;<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.linux-container-executor.cgroups.mount<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.linux-container-executor.cgroups.mount-path<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>/sys/fs/cgroup<span class="tag">&lt;<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>


<h3 id="4-CPU-资源限制："><a href="#4-CPU-资源限制：" class="headerlink" title="4. CPU 资源限制："></a>4. CPU 资源限制：</h3><p>NM 主要使用两个参数来限制 containers CPU 资源使用。</p>
<p>首先，使用 <code>yarn.nodemanager.resource.percentage-physical-cpu-limit</code> 来设置所有 containers 的总的 CPU 使用率占用总的 CPU 资源的百分比。比如设置为 60，则所有的 containers 的 CPU 使用总和在任何情况下都不会超过机器总体 CPU 资源的 60 %。</p>
<p>然后，使用 <code>yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage</code> 设置是否对 container 的 CPU 使用进行严格限制。如果设置为 true ，即便 NM 的 CPU 资源比较空闲， containers CPU 使用率也不能超过限制，这种配置下，可以严格限制 CPU 使用，保证每个 container 只能使用自己分配到的 CPU 资源。但是如果设置为 false ，container 可以在 NM 有空闲 CPU 资源时，超额使用 CPU，这种模式下，可以保证 NM 总体 CPU 使用率比较高，提升集群的计算性能和吞吐量，所以建议使用非严格的限制方式（实际通过 CGroup 的 cpu share 功能实现）。不论这个值怎么设置，所有 containers 总的 CPU 使用率都不会超过 cpu-limit 设置的值。</p>
<p>NM 会按照机器总的 <code>CPU num* limit-percent</code> 来计算 NM 总体可用的实际 CPU 资源，然后根据 NM 配置的 Vcore 数量来计算每个 Vcore 对应的实际 CPU 资源，再乘以 container 申请的 Vcore 数量计算 container 的实际可用的 CPU 资源。这里需要注意的是，在计算总体可用的 CPU 核数时，NM 默认使用的实际的物理核数，而一个物理核通常会对应多个逻辑核（单核多线程），而且我们默认的 CPU 核数通常都是逻辑核，所以我们需要设置 <code>yarn.nodemanager.resource.count-logical-processors-as-cores</code> 为 true 来指定使用逻辑核来计算 CPU 资源。</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.percentage-physical-cpu-limit<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>80<span class="tag">&lt;<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>    </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.count-logical-processors-as-cores<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><p>Linux 内核版本 <code>3.10.0-327.el7.x86_64</code> 上 Yarn 启用 CGroup 功能后，会触发内核 BUG，导致内核卡死，重启，NM 挂掉，所有运行的任务失败。所以如果需要启用 CGroup 功能，绝对不能使用<code>3.10.0-327.el7.x86_64</code> 版本内核。亲测升级内核版本可解决该问题。</p>
<p>参见 <a href="https://runitao.github.io/a-process-to-reproduce-kernel-crash.html" target="_blank" rel="noopener">一次重现内核 Bug 的经历</a></p>
<h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><ol>
<li><a href="https://tech.meituan.com/2015/03/31/cgroups.html" target="_blank" rel="noopener">Linux资源管理之cgroups简介</a>    </li>
<li><a href="https://coolshell.cn/articles/17049.html" target="_blank" rel="noopener">DOCKER基础技术：LINUX CGROUP</a>   </li>
<li><a href="https://hadoop.apache.org/docs/r3.2.0/hadoop-yarn/hadoop-yarn-site/NodeManagerCgroups.html" target="_blank" rel="noopener">Using CGroups with YARN</a></li>
<li><a href="https://runitao.github.io/a-process-to-reproduce-kernel-crash.html" target="_blank" rel="noopener">一次重现内核 Bug 的经历</a></li>
</ol>
]]></content>
      <categories>
        <category>Hadoop-YARN</category>
      </categories>
      <tags>
        <tag>Yarn</tag>
        <tag>Cgroup</tag>
        <tag>资源限制</tag>
      </tags>
  </entry>
  <entry>
    <title>Yarn ContainerExecutor 配置与使用</title>
    <url>/2019/10/12/yarn-container-executor/</url>
    <content><![CDATA[<p>在 Yarn 的架构中，将集群中的计算资源，主要是内存和 CPU ，封装抽象出了 Container 的概念， 类似于 <code>container_001 &lt;memory:2048, vCores:1&gt;</code>。 Container 由 ResourceManager 负责调度与分配，由资源所在的 NodeManager 负责启动与管理。</p><a id="more"></a>
<p>Container 所封装的计算资源是由集群中的 NodeManager 提供的，所以 Container 的启动，运行，监控， 管理也需要对应的 NodeManager 来执行。 ContainerExecutor 正是 NodeManager 用来启动与管理 Container 的工具。</p>
<p>Yarn 3.0 版本中，在 Linux 系统环境下，ContainerExecutor 有两种实现：</p>
<ul>
<li>DefaultContainerExecutor:   简称 DCE ,如其名，是默认的 ContainerExecutor 实现。 如果用户未指定 ContainerExecutor 的具体实现，NM 就会使用它。 DCE 直接使用 bash 来启动 container 进程，所有 container 都使用 NM 进程用户 (yarn) 启动。</li>
</ul>
<ul>
<li>LinuxContainerExecutor:   简称 LCE，相比于 DCE ，它能提供更多有用的功能，如用户权限隔离，支持使用提交任务用户来启动 container；支持使用 cgroup 进行资源限制； 支持运行 docker container (合并了 2.x 版本中的 DockerContainerExecutor)。 LCE 使用可执行的二进制文件 container-executor 来启动 container 进程，container 的用户根据配置可以统一使用默认用户，也可以使用提交任务的用户（需要提前在 NM 上添加所有支持的用户）。</li>
</ul>
<p><strong>LCE 是安全的 ContainerExecutor</strong>。在默认的情况下，如果我们的集群是 non-secure ，而且没有什么特殊需求时，使用 DCE 就足够了，因为 DCE 配置和使用都很简单。但是当我们的集群要求安全性，比如开启了 kerberos 验证，我们就必须使用 LCE，使用 DCE 的话 MR 任务会在 reduce shuffle 阶段失败退出，参见<a href="https://issues.apache.org/jira/browse/YARN-1432" target="_blank" rel="noopener">YARN-1432</a>。</p>
<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>NM 具体使用哪种 ContainerExecutor 的实现由 yarn-site.xml 里的 <code>yarn.nodemanager.container-executor.class</code> 属性来配置。</p>
<h3 id="DefaultContainerExecutor"><a href="#DefaultContainerExecutor" class="headerlink" title="DefaultContainerExecutor"></a>DefaultContainerExecutor</h3><p>DCE 的配置比较简单，只需要在 yarn-site.xml 指定 <code>yarn.nodemanager.container-executor.class</code> 属性为 <code>org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor</code> 即可，不需要额外的配置。</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.container-executor.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="LinuxContainerExecutor"><a href="#LinuxContainerExecutor" class="headerlink" title="LinuxContainerExecutor"></a>LinuxContainerExecutor</h3><p>LCE 配置相对更加复杂一些， 具体如下：</p>
<p><strong>1. yarn-site.xml 配置</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- NM 的 Unix 用户组，需要跟 container-executor.cfg 里面的配置一致，主要用来验证是否有安全访问 container-executor 二进制的权限 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.linux-container-executor.group<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 集群在 nonsecure 模式时，是否限制 container 的启动用户，true：container 使用统一的用户启动 false: container 使用任务用户启动 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 集群在 nonsecure 模式时，且开启 container 启动用户限制时，统一使用的用户，如果不设置，默认为 nobody --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>2. container-executor.cfg 配置</strong></p>
<p>container-executor.cfg 是 container-executor 二进制程序的配置文件，会在其启动时读取校验。<br>具体的属性如下：</p>
<ul>
<li>yarn.nodemanager.linux-container-executor.group: NM 的 Unix 用户组， 需要与 yarn-site.xml 里一致。</li>
<li>allowed.system.users: 允许使用的系统用户，多个用户使用 ‘,’ 分隔，可以不设置，即允许所有用户。</li>
<li>banned.users: 禁止使用的用户，多个用户使用 ‘,’ 分隔。</li>
<li>min.user.id: 允许使用的用户的 uid 最小值，防止有其他超级用户。</li>
</ul>
<p>配置样例如下：</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="meta">yarn.nodemanager.linux-container-executor.group</span>=<span class="string">hadoop</span></span><br><span class="line"><span class="meta">allowed.system.users</span>=<span class="string">hdfs,yarn,mapred,</span></span><br><span class="line"><span class="meta">banned.users</span>=<span class="string">root,bin</span></span><br><span class="line"><span class="meta">min.user.id</span>=<span class="string">100</span></span><br></pre></td></tr></table></figure>

<h2 id="启用"><a href="#启用" class="headerlink" title="启用"></a>启用</h2><p>DCE 的启用不需要额外的操作，配置完成后直接重启 NM 即可。LCE 的启用则还需要一系列的准备工作。</p>
<p><strong>1. 设置 container-executor 权限</strong>    </p>
<p>container-executor 二进制的 owner 必须是 root，属组必须与 NM 属组相同 (hadoop)，同时，它的权限必须设置成为 6050，以赋予它 setuid 的权限，来实现使用不同的用户来启动 container。</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">chown root:hadoop /usr/lib/hadoop-yarn/bin/container-executor </span><br><span class="line">chmod 6050 /usr/lib/hadoop-yarn/bin/container-executor</span><br></pre></td></tr></table></figure>

<p><strong>2. 设置 container-executor.cfg 权限</strong>    </p>
<p>container-executor.cfg 二进制的 owner 必须是 root，属组必须与 NM 属组相同 (hadoop)，同时，它的权限必须设置成为 0400， 以保证它是只读不可写的</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">chown root:hadoop /etc/hadoop/conf/container-executor.cfg</span><br><span class="line">chmode 0400 /etc/hadoop/conf/container-executor.cfg</span><br></pre></td></tr></table></figure>

<p><strong>3. 设置 yarn-local 和 yarn-log dirs 权限</strong>    </p>
<p>所有配置的 yarn-local 和 yarn-log 目录属主必须是 yarn:hadoop ，这个一般集群搭建时已经修改好了，不需要再处理。</p>
<p><strong>4. 任务用户管理</strong>    </p>
<p>在<strong>集群未开启 security authentication 时，也就是集群的用户校验方式为 <code>hadoop.security.authentication=simple</code> 时</strong>，如果开启用户限制<code>yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users=false</code>，也就是说使用任务提交用户来运行其 container 时，则需要提前在集群所有的 NM 节点上将需要的用户通过 useradd 命令，逐个添加到机器上，否则任务运行时会因为找不到指定用户而失败。当集群规模比较大，用户很多时，添加用户还是比较繁琐的，也不好维护，所以以我们的实践经验来看，建议开启用户限制，统一使用 yarn 用户来启动 container。</p>
<p>不过当集群在 security 模式时，基本上就是开启kerberos 做权限验证时，只允许使用任务提交用户来启动 container，这时就比较苦逼的需要把 YARN 集群里的用户都添加到 NM 节点上才行。不过为了不这么麻烦，我对这块逻辑进行了修改，允许在安全下依然可以使用统一 yarn 用户来执行用户任务。具体实现方式可以查看<a href="yarn-limit-user-in-secure-mode">YARN 在安全模式下使用统一用户运行 container</a>。</p>
<p>当上述的操作都完成后，重启 NM ， LCE 就会被启用。</p>
<h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><p>container-executor 和 container-executor.cfg 文件的权限一定要按照要求修改，否则 NM 会启动失败。如果改了权限后，NM 还是报权限问题，还需要将文件所在的目录用户组也改成 root:hadoop，权限改成 755。</p>
<h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><ul>
<li><a href="https://www.ibm.com/support/knowledgecenter/en/SSPT3X_4.2.0/com.ibm.swg.im.infosphere.biginsights.install.doc/doc/inst_adv_yarn_config.html" target="_blank" rel="noopener">Configuring YARN container executor</a></li>
<li><a href="https://hadoop.apache.org/docs/r3.2.0/hadoop-yarn/hadoop-yarn-site/SecureContainer.html" target="_blank" rel="noopener">YARN Secure Containers</a></li>
<li><a href="https://makeling.github.io/bigdata/dcb921f7.html" target="_blank" rel="noopener">理解和配置LinuxContainerExecutor
</a></li>
</ul>
]]></content>
      <categories>
        <category>Hadoop-YARN</category>
      </categories>
      <tags>
        <tag>Yarn</tag>
        <tag>ContainerExecutor</tag>
        <tag>LinuxContainerExecutor</tag>
      </tags>
  </entry>
  <entry>
    <title>写在最开始的话</title>
    <url>/2019/10/08/hello-world/</url>
    <content><![CDATA[<p>懒了这么久，终于还是下定决心开始写博客了。</p>
<p>博客的内容主要就是总结一下日常工作和学习中遇到的知识点和经验，将自己的技能点记录沉淀下来，也能更好的鞭策自己不断前行。</p>
<p>九层之台，起于累土，千里之行，始于足下。希望自己能坚持下来。</p>
<p>Keep coding, keep learning.</p>
]]></content>
      <categories>
        <category>其他</category>
      </categories>
  </entry>
</search>
